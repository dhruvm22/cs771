{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**submit.py**"
      ],
      "metadata": {
        "id": "riYgSgEUtybS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmXgjm6hoQRi",
        "outputId": "ad74dc6a-242a-4d6c-a0e1-641170d8ae5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights and bias for Response0:\n",
            "[  1.05881585   0.0414974   -0.21852695 ...  -0.23522568   4.16288809\n",
            " -11.57132579] -0.44031316063134335\n",
            "Weights and bias for Response1:\n",
            "[ 0.32937379  0.56387337 -0.18190241 ...  0.24336342  0.82469004\n",
            " -1.77593718] -4.6175742173938135\n",
            "Test accuracy for Response0: 0.9863\n",
            "Test accuracy for Response1: 0.9943\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "from scipy.linalg import khatri_rao\n",
        "\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "def my_fit(X_train, y0_train, y1_train):\n",
        "    ################################\n",
        "    #  Non Editable Region Ending  #\n",
        "    ################################\n",
        "\n",
        "    # Map challenges to higher dimensional space\n",
        "    X_mapped = my_map(X_train)\n",
        "\n",
        "    # Train model for Response0\n",
        "    clf0 = LinearSVC()\n",
        "    clf0.fit(X_mapped, y0_train)\n",
        "\n",
        "    # Train model for Response1\n",
        "    clf1 = LinearSVC()\n",
        "    clf1.fit(X_mapped, y1_train)\n",
        "\n",
        "    # Extract weights and biases\n",
        "    w0 = clf0.coef_.flatten()\n",
        "    b0 = clf0.intercept_[0]\n",
        "\n",
        "    w1 = clf1.coef_.flatten()\n",
        "    b1 = clf1.intercept_[0]\n",
        "\n",
        "    return w0, b0, w1, b1\n",
        "\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "def my_map(X):\n",
        "    ################################\n",
        "    #  Non Editable Region Ending  #\n",
        "    ################################\n",
        "    num_features = X.shape[1]\n",
        "    num_samples = X.shape[0]\n",
        "    num_mapped_features = num_features ** 2\n",
        "\n",
        "    # Initialize the mapped features matrix\n",
        "    mapped_features = np.zeros((num_samples, num_mapped_features))\n",
        "\n",
        "    # Iterate over rows and compute Khatri-Rao product for each row\n",
        "    for i in range(num_samples):\n",
        "        row = X[i, :].reshape(1, -1)  # Reshape row to a 2D array\n",
        "        row_result = khatri_rao(row.T, row.T)  # Compute Khatri-Rao for the row, transposed\n",
        "        mapped_features[i, :] = row_result.flatten()\n",
        "\n",
        "    return mapped_features\n",
        "\n",
        "def validate():\n",
        "    # Example file paths\n",
        "    train_file = \"public_trn.txt\"\n",
        "    test_file = \"public_tst.txt\"\n",
        "\n",
        "    # Load data\n",
        "    X_train, y0_train, y1_train = load_data(train_file)\n",
        "\n",
        "    # Fit the model\n",
        "    w0, b0, w1, b1 = my_fit(X_train, y0_train, y1_train)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"Weights and bias for Response0:\")\n",
        "    print(w0, b0)\n",
        "    print(\"Weights and bias for Response1:\")\n",
        "    print(w1, b1)\n",
        "\n",
        "    # Load test data (assuming we want to validate on the same data format)\n",
        "    X_test, y0_test, y1_test = load_data(test_file)\n",
        "\n",
        "    # Map the test data\n",
        "    X_test_mapped = my_map(X_test)\n",
        "\n",
        "    # Predict responses\n",
        "    y0_pred = np.sign(X_test_mapped @ w0 + b0)\n",
        "    y1_pred = np.sign(X_test_mapped @ w1 + b1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy0 = np.mean((y0_pred > 0) == y0_test)\n",
        "    accuracy1 = np.mean((y1_pred > 0) == y1_test)\n",
        "\n",
        "    print(\"Test accuracy for Response0:\", accuracy0)\n",
        "    print(\"Test accuracy for Response1:\", accuracy1)\n",
        "\n",
        "def load_data(file_path):\n",
        "    # Load training data\n",
        "    data = np.loadtxt(file_path, delimiter=\" \")\n",
        "    X = data[:, :32]\n",
        "    y0 = data[:, 32]\n",
        "    y1 = data[:, 33]\n",
        "    return X, y0, y1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6**"
      ],
      "metadata": {
        "id": "c0K8ilqYt5iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data function\n",
        "def load_data(file_path):\n",
        "    data = np.loadtxt(file_path, delimiter=\" \")\n",
        "    X = data[:, :32]\n",
        "    y0 = data[:, 32]\n",
        "    y1 = data[:, 33]\n",
        "    return X, y0, y1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ################################\n",
        "def my_map(X):\n",
        "    ################################\n",
        "    #  Non Editable Region Ending  #\n",
        "    ################################\n",
        "    num_features = X.shape[1]\n",
        "    num_samples = X.shape[0]\n",
        "    num_mapped_features = num_features ** 2\n",
        "\n",
        "    # Initialize the mapped features matrix\n",
        "    mapped_features = np.zeros((num_samples, num_mapped_features))\n",
        "\n",
        "    # Iterate over rows and compute Khatri-Rao product for each row\n",
        "    for i in range(num_samples):\n",
        "        row = X[i, :].reshape(1, -1)  # Reshape row to a 2D array\n",
        "        row_result = khatri_rao(row.T, row.T)  # Compute Khatri-Rao for the row, transposed\n",
        "        mapped_features[i, :] = row_result.flatten()\n",
        "\n",
        "    return mapped_features\n",
        "\n",
        "# Training and evaluation function\n",
        "def train_and_evaluate(X_train, y0_train, y1_train, X_test, y0_test, y1_test, model, **kwargs):\n",
        "    X_train_mapped = my_map(X_train)\n",
        "    X_test_mapped = my_map(X_test)\n",
        "\n",
        "    clf0 = model(**kwargs)\n",
        "    clf1 = model(**kwargs)\n",
        "\n",
        "    start_time = time.time()\n",
        "    clf0.fit(X_train_mapped, y0_train)\n",
        "    clf1.fit(X_train_mapped, y1_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    y0_pred = clf0.predict(X_test_mapped)\n",
        "    y1_pred = clf1.predict(X_test_mapped)\n",
        "\n",
        "    accuracy0 = accuracy_score(y0_test, y0_pred)\n",
        "    accuracy1 = accuracy_score(y1_test, y1_pred)\n",
        "\n",
        "    return training_time, accuracy0, accuracy1\n",
        "\n",
        "# Load data\n",
        "X_train, y0_train, y1_train = load_data(\"public_trn.txt\")\n",
        "X_test, y0_test, y1_test = load_data(\"public_tst.txt\")\n",
        "\n",
        "# Experiments setup\n",
        "experiments = [\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_default\", \"kwargs\": {}},\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_hinge\", \"kwargs\": {\"loss\": \"hinge\"}},\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_squared_hinge\", \"kwargs\": {\"loss\": \"squared_hinge\"}},\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_C_high\", \"kwargs\": {\"C\": 10}},\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_C_low\", \"kwargs\": {\"C\": 0.1}},\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_tol_high\", \"kwargs\": {\"tol\": 1e-1}},\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_tol_low\", \"kwargs\": {\"tol\": 1e-5}},\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_penalty_l2\", \"kwargs\": {\"penalty\": \"l2\"}},\n",
        "    {\"model\": LinearSVC, \"name\": \"LinearSVC_penalty_l1\", \"kwargs\": {\"penalty\": \"l1\", \"dual\": False}},\n",
        "    {\"model\": LogisticRegression, \"name\": \"LogisticRegression_default\", \"kwargs\": {}},\n",
        "    {\"model\": LogisticRegression, \"name\": \"LogisticRegression_C_high\", \"kwargs\": {\"C\": 10}},\n",
        "    {\"model\": LogisticRegression, \"name\": \"LogisticRegression_C_low\", \"kwargs\": {\"C\": 0.1}},\n",
        "    {\"model\": LogisticRegression, \"name\": \"LogisticRegression_tol_high\", \"kwargs\": {\"tol\": 1e-1}},\n",
        "    {\"model\": LogisticRegression, \"name\": \"LogisticRegression_tol_low\", \"kwargs\": {\"tol\": 1e-5}},\n",
        "    {\"model\": LogisticRegression, \"name\": \"LogisticRegression_penalty_l2\", \"kwargs\": {\"penalty\": \"l2\"}},\n",
        "    {\"model\": LogisticRegression, \"name\": \"LogisticRegression_penalty_l1\", \"kwargs\": {\"penalty\": \"l1\", \"solver\": \"liblinear\"}}\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for experiment in experiments:\n",
        "    training_time, accuracy0, accuracy1 = train_and_evaluate(\n",
        "        X_train, y0_train, y1_train, X_test, y0_test, y1_test, experiment[\"model\"], **experiment[\"kwargs\"]\n",
        "    )\n",
        "    results.append({\n",
        "        \"Experiment\": experiment[\"name\"],\n",
        "        \"Training Time (s)\": training_time,\n",
        "        \"Accuracy0\": accuracy0,\n",
        "        \"Accuracy1\": accuracy1\n",
        "    })\n",
        "\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FNNscUiCtmA_",
        "outputId": "9c5e03f0-980c-4c38-aff5-349188e46f94",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'khatri_rao' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b15a9a0c3ce1>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     training_time, accuracy0, accuracy1 = train_and_evaluate(\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-1-b15a9a0c3ce1>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(X_train, y0_train, y1_train, X_test, y0_test, y1_test, model, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Training and evaluation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mX_train_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mX_test_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-b15a9a0c3ce1>\u001b[0m in \u001b[0;36mmy_map\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape row to a 2D array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mrow_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkhatri_rao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute Khatri-Rao for the row, transposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mmapped_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'khatri_rao' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6: Code 2**"
      ],
      "metadata": {
        "id": "KWmSJDwLyQIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  import numpy as np\n",
        "  import time\n",
        "  from sklearn.svm import LinearSVC\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  import pandas as pd\n",
        "  from sklearn.exceptions import ConvergenceWarning\n",
        "  import warnings\n",
        "  from scipy.linalg import khatri_rao\n",
        "\n",
        "  # Load data function\n",
        "  def load_data(file_path):\n",
        "      data = np.loadtxt(file_path, delimiter=\" \")\n",
        "      X = data[:, :32]\n",
        "      y0 = data[:, 32]\n",
        "      y1 = data[:, 33]\n",
        "      return X, y0, y1\n",
        "\n",
        "  # Map challenges to higher dimensional space using Khatri-Rao product\n",
        "\n",
        "def my_map(X):\n",
        "\n",
        "    num_features = X.shape[1]\n",
        "    num_samples = X.shape[0]\n",
        "    num_mapped_features = num_features ** 2\n",
        "\n",
        "\n",
        "    mapped_features = np.zeros((num_samples, num_mapped_features))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        row = X[i, :].reshape(1, -1)\n",
        "        row_result = khatri_rao(row.T, row.T)\n",
        "        mapped_features[i, :] = row_result.flatten()\n",
        "\n",
        "    return mapped_features\n",
        "\n",
        "  # Training and evaluation function\n",
        "  def train_and_evaluate(X_train, y0_train, y1_train, X_test, y0_test, y1_test, model, **kwargs):\n",
        "      scaler = StandardScaler()\n",
        "      X_train = scaler.fit_transform(X_train)\n",
        "      X_test = scaler.transform(X_test)\n",
        "\n",
        "      X_train_mapped = my_map(X_train)\n",
        "      X_test_mapped = my_map(X_test)\n",
        "\n",
        "      clf0 = model(max_iter=5000, **kwargs)\n",
        "      clf1 = model(max_iter=5000, **kwargs)\n",
        "\n",
        "      start_time = time.time()\n",
        "      with warnings.catch_warnings():\n",
        "          warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "          clf0.fit(X_train_mapped, y0_train)\n",
        "          clf1.fit(X_train_mapped, y1_train)\n",
        "      training_time = time.time() - start_time\n",
        "\n",
        "      y0_pred = clf0.predict(X_test_mapped)\n",
        "      y1_pred = clf1.predict(X_test_mapped)\n",
        "\n",
        "      accuracy0 = accuracy_score(y0_test, y0_pred)\n",
        "      accuracy1 = accuracy_score(y1_test, y1_pred)\n",
        "\n",
        "      return training_time, accuracy0, accuracy1\n",
        "\n",
        "  # Load data\n",
        "  X_train, y0_train, y1_train = load_data(\"public_trn.txt\")\n",
        "  X_test, y0_test, y1_test = load_data(\"public_tst.txt\")\n",
        "\n",
        "  # Experiments setup\n",
        "  experiments = [\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_default\", \"kwargs\": {}},\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_hinge\", \"kwargs\": {\"loss\": \"hinge\"}},\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_squared_hinge\", \"kwargs\": {\"loss\": \"squared_hinge\"}},\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_C_high\", \"kwargs\": {\"C\": 10}},\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_C_low\", \"kwargs\": {\"C\": 0.1}},\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_tol_high\", \"kwargs\": {\"tol\": 1e-1}},\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_tol_low\", \"kwargs\": {\"tol\": 1e-5}},\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_penalty_l2\", \"kwargs\": {\"penalty\": \"l2\"}},\n",
        "      {\"model\": LinearSVC, \"name\": \"LinearSVC_penalty_l1\", \"kwargs\": {\"penalty\": \"l1\", \"dual\": False}},\n",
        "      {\"model\": LogisticRegression, \"name\": \"LogisticRegression_default\", \"kwargs\": {}},\n",
        "      {\"model\": LogisticRegression, \"name\": \"LogisticRegression_C_high\", \"kwargs\": {\"C\": 10}},\n",
        "      {\"model\": LogisticRegression, \"name\": \"LogisticRegression_C_low\", \"kwargs\": {\"C\": 0.1}},\n",
        "      {\"model\": LogisticRegression, \"name\": \"LogisticRegression_tol_high\", \"kwargs\": {\"tol\": 1e-1}},\n",
        "      {\"model\": LogisticRegression, \"name\": \"LogisticRegression_tol_low\", \"kwargs\": {\"tol\": 1e-5}},\n",
        "      {\"model\": LogisticRegression, \"name\": \"LogisticRegression_penalty_l2\", \"kwargs\": {\"penalty\": \"l2\"}},\n",
        "      {\"model\": LogisticRegression, \"name\": \"LogisticRegression_penalty_l1\", \"kwargs\": {\"penalty\": \"l1\", \"solver\": \"liblinear\"}}\n",
        "  ]\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for experiment in experiments:\n",
        "      training_time, accuracy0, accuracy1 = train_and_evaluate(\n",
        "          X_train, y0_train, y1_train, X_test, y0_test, y1_test, experiment[\"model\"], **experiment[\"kwargs\"]\n",
        "      )\n",
        "      results.append({\n",
        "          \"Experiment\": experiment[\"name\"],\n",
        "          \"Training Time (s)\": training_time,\n",
        "          \"Accuracy0\": accuracy0,\n",
        "          \"Accuracy1\": accuracy1\n",
        "      })\n",
        "\n",
        "  results_df = pd.DataFrame(results)\n",
        "  print(results_df)"
      ],
      "metadata": {
        "id": "i6m168nkyVg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another approach\n"
      ],
      "metadata": {
        "id": "eR4u3C3QRu-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "from scipy.linalg import khatri_rao\n",
        "import time\n",
        "\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "def my_fit(X_train, y0_train, y1_train):\n",
        "    ################################\n",
        "    #  Non Editable Region Ending  #\n",
        "    ################################\n",
        "\n",
        "    # Map challenges to higher dimensional space\n",
        "    X_mapped = my_map(X_train)\n",
        "\n",
        "    # Train model for Response0\n",
        "    clf0 = LinearSVC(loss='squared_hinge')\n",
        "    clf0.fit(X_mapped, y0_train)\n",
        "\n",
        "    # Train model for Response1\n",
        "    clf1 = LinearSVC(loss='squared_hinge')\n",
        "    clf1.fit(X_mapped, y1_train)\n",
        "\n",
        "    # Extract weights and biases\n",
        "    w0 = clf0.coef_.flatten()\n",
        "    b0 = clf0.intercept_[0]\n",
        "\n",
        "    w1 = clf1.coef_.flatten()\n",
        "    b1 = clf1.intercept_[0]\n",
        "\n",
        "    return w0, b0, w1, b1\n",
        "\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "def my_map(X):\n",
        "    ################################\n",
        "    #  Non Editable Region Ending  #\n",
        "    ################################\n",
        "    num_features = X.shape[1]\n",
        "    num_samples = X.shape[0]\n",
        "    num_mapped_features = num_features ** 2\n",
        "\n",
        "    # Initialize the mapped features matrix\n",
        "    mapped_features = np.zeros((num_samples, num_mapped_features))\n",
        "\n",
        "    # Iterate over rows and compute Khatri-Rao product for each row\n",
        "    for i in range(num_samples):\n",
        "        row = X[i, :].reshape(1, -1)  # Reshape row to a 2D array\n",
        "        row_result = khatri_rao(row.T, row.T)  # Compute Khatri-Rao for the row, transposed\n",
        "        mapped_features[i, :] = row_result.flatten()\n",
        "\n",
        "    return mapped_features\n",
        "\n",
        "def validate():\n",
        "    # Example file paths\n",
        "    train_file = \"public_trn.txt\"\n",
        "    test_file = \"public_tst.txt\"\n",
        "\n",
        "    # Load data\n",
        "    X_train, y0_train, y1_train = load_data(train_file)\n",
        "    start_time = time.time()\n",
        "    # Fit the model\n",
        "    w0, b0, w1, b1 = my_fit(X_train, y0_train, y1_train)\n",
        "    training_time = time.time() - start_time\n",
        "    # Print the results\n",
        "    print(\"Weights and bias for Response0:\")\n",
        "    print(w0, b0)\n",
        "    print(\"Weights and bias for Response1:\")\n",
        "    print(w1, b1)\n",
        "\n",
        "    # Load test data (assuming we want to validate on the same data format)\n",
        "    X_test, y0_test, y1_test = load_data(test_file)\n",
        "\n",
        "    # Map the test data\n",
        "    X_test_mapped = my_map(X_test)\n",
        "\n",
        "    # Predict responses\n",
        "    y0_pred = np.sign(X_test_mapped @ w0 + b0)\n",
        "    y1_pred = np.sign(X_test_mapped @ w1 + b1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy0 = np.mean((y0_pred > 0) == y0_test)\n",
        "    accuracy1 = np.mean((y1_pred > 0) == y1_test)\n",
        "\n",
        "    print(\"Test accuracy for Response0:\", accuracy0)\n",
        "    print(\"Test accuracy for Response1:\", accuracy1)\n",
        "    print(\"Training time:\", training_time)\n",
        "\n",
        "def load_data(file_path):\n",
        "    # Load training data\n",
        "    data = np.loadtxt(file_path, delimiter=\" \")\n",
        "    X = data[:, :32]\n",
        "    y0 = data[:, 32]\n",
        "    y1 = data[:, 33]\n",
        "    return X, y0, y1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    validate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WbyaXFVJopA",
        "outputId": "61d74150-28e6-4479-9196-07e8edadfd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights and bias for Response0:\n",
            "[  1.04937987   0.0425067   -0.2190335  ...  -0.23247338   4.16335398\n",
            " -11.57396672] -0.4344516324798803\n",
            "Weights and bias for Response1:\n",
            "[ 0.33243872  0.56453659 -0.179414   ...  0.24640007  0.82631344\n",
            " -1.77302364] -4.617000923881357\n",
            "Test accuracy for Response0: 0.9847\n",
            "Test accuracy for Response1: 0.9943\n",
            "Training time: 7.6211066246032715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}